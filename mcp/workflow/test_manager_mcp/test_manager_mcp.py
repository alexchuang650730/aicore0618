#!/usr/bin/env python3
"""
<<<<<<< HEAD
Enhanced Test Manager MCP - å¢å¼ºçš„æµ‹è¯•ç®¡ç†å™¨å·¥ä½œæµ
é›†æˆæ™ºèƒ½æµ‹è¯•ç­–ç•¥ç”Ÿæˆã€ç”¨ä¾‹ç”Ÿæˆå’Œæ‰§è¡Œç®¡ç†åŠŸèƒ½
=======
Test Manager MCP - æµ‹è¯•ç®¡ç†å™¨å·¥ä½œæµ
åŸºäºç°æœ‰çš„PowerAutomationæµ‹è¯•æ¡†æ¶ï¼Œæä¾›ç»Ÿä¸€çš„æµ‹è¯•ç®¡ç†å’Œæ‰§è¡Œèƒ½åŠ›
>>>>>>> fc1525368711230da2586d4c928810f1e886598c
è¿è¡Œåœ¨8097ç«¯å£
"""

import asyncio
import json
import sys
import os
from pathlib import Path
from flask import Flask, request, jsonify
from flask_cors import CORS
from datetime import datetime
import logging
<<<<<<< HEAD
from typing import Dict, List, Any, Optional

# å¯¼å…¥å¢å¼ºçš„æµ‹è¯•ç®¡ç†ç»„ä»¶
from enhanced_strategy_generator import EnhancedTestStrategyGenerator
from enhanced_case_generator import EnhancedTestCaseGenerator
from enhanced_execution_manager import EnhancedTestExecutionManager
=======
>>>>>>> fc1525368711230da2586d4c928810f1e886598c

# æ·»åŠ æµ‹è¯•æ¡†æ¶è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent / "test"))

try:
    from framework.test_manager import get_test_manager, TestManager
    from framework.test_discovery import TestDiscovery
    from framework.test_runner import TestRunner
    from framework.test_reporter import TestReporter
except ImportError as e:
    logging.error(f"æ— æ³•å¯¼å…¥æµ‹è¯•æ¡†æ¶: {e}")
    # åˆ›å»ºç®€åŒ–çš„æµ‹è¯•ç®¡ç†å™¨
    class TestManager:
        def __init__(self):
            self.logger = logging.getLogger(__name__)
        
        async def discover_tests(self, **kwargs):
            return []
        
        async def run_tests(self, **kwargs):
            return {"status": "error", "message": "æµ‹è¯•æ¡†æ¶æœªæ­£ç¡®å®‰è£…"}

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

<<<<<<< HEAD
class EnhancedTestManagerMCP:
    """å¢å¼ºçš„æµ‹è¯•ç®¡ç†å™¨MCP - é›†æˆæ™ºèƒ½æµ‹è¯•ç®¡ç†èƒ½åŠ›"""
    
    def __init__(self):
        self.service_id = "enhanced_test_manager_mcp"
        self.version = "2.0.0"
        self.status = "running"
        
        # åˆå§‹åŒ–å¢å¼ºç»„ä»¶
        self.strategy_generator = EnhancedTestStrategyGenerator()
        self.case_generator = EnhancedTestCaseGenerator()
        self.execution_manager = EnhancedTestExecutionManager()
        
        # åˆå§‹åŒ–åŸæœ‰æµ‹è¯•ç®¡ç†å™¨
=======
class TestManagerMCP:
    """æµ‹è¯•ç®¡ç†å™¨MCP - åŒ…è£…ç°æœ‰çš„æµ‹è¯•æ¡†æ¶"""
    
    def __init__(self):
        self.service_id = "test_manager_mcp"
        self.version = "1.0.0"
        self.status = "running"
        
        # åˆå§‹åŒ–æµ‹è¯•ç®¡ç†å™¨
>>>>>>> fc1525368711230da2586d4c928810f1e886598c
        try:
            self.test_manager = get_test_manager()
            logger.info("âœ… æˆåŠŸè¿æ¥åˆ°PowerAutomationæµ‹è¯•æ¡†æ¶")
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•æ¡†æ¶åˆå§‹åŒ–å¤±è´¥: {e}")
            self.test_manager = TestManager()  # ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
        
<<<<<<< HEAD
        logger.info(f"âœ… Enhanced Test Manager MCP åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ğŸ§  æ™ºèƒ½æµ‹è¯•ç­–ç•¥ç”Ÿæˆå™¨: å°±ç»ª")
        logger.info(f"ğŸ“ æ™ºèƒ½æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨: å°±ç»ª")
        logger.info(f"âš¡ å¼‚æ­¥æµ‹è¯•æ‰§è¡Œç®¡ç†å™¨: å°±ç»ª")
    
    async def process(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æµ‹è¯•ç®¡ç†è¯·æ±‚ - å¢å¼ºç‰ˆæœ¬"""
        request_type = data.get("type")
        
        try:
            if request_type == "generate_strategy":
                return await self.strategy_generator.generate_strategy_for_remote(
                    data.get("project_info", {})
                )
            elif request_type == "generate_cases":
                return await self.case_generator.generate_cases_for_remote(
                    data.get("strategy", {}),
                    data.get("requirements", {})
                )
            elif request_type == "execute_tests":
                execution_id = await self.execution_manager.execute_for_remote(
                    data.get("test_cases", []),
                    data.get("execution_config", {})
                )
                return {
                    "success": True,
                    "execution_id": execution_id,
                    "message": "æµ‹è¯•æ‰§è¡Œå·²å¯åŠ¨"
                }
            elif request_type == "get_execution_status":
                return self.execution_manager.get_execution_status(
                    data.get("execution_id")
                )
            elif request_type == "get_execution_report":
                return self.execution_manager.get_execution_report(
                    data.get("execution_id")
                )
            elif request_type == "get_active_executions":
                return {
                    "success": True,
                    "active_executions": self.execution_manager.get_active_executions()
                }
            elif request_type == "cancel_execution":
                success = await self.execution_manager.cancel_execution(
                    data.get("execution_id")
                )
                return {
                    "success": success,
                    "message": "æ‰§è¡Œå·²å–æ¶ˆ" if success else "æ‰§è¡Œæœªæ‰¾åˆ°æˆ–æ— æ³•å–æ¶ˆ"
                }
            elif request_type == "full_intelligent_cycle":
                # å®Œæ•´æ™ºèƒ½æµ‹è¯•å‘¨æœŸ
                return await self._execute_full_intelligent_cycle(data)
            else:
                # å›é€€åˆ°åŸæœ‰åŠŸèƒ½
                return await self._handle_legacy_request(request_type, data)
                
        except Exception as e:
            logger.error(f"å¤„ç†è¯·æ±‚å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "request_type": request_type
            }
    
    async def _execute_full_intelligent_cycle(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„æ™ºèƒ½æµ‹è¯•å‘¨æœŸ"""
        project_info = data.get("project_info", {})
        
        try:
            # 1. ç”Ÿæˆæ™ºèƒ½æµ‹è¯•ç­–ç•¥
            logger.info("ğŸ§  ç”Ÿæˆæ™ºèƒ½æµ‹è¯•ç­–ç•¥...")
            strategy_result = await self.strategy_generator.generate_strategy_for_remote(project_info)
            
            if not strategy_result.get("success", False):
                return {
                    "success": False,
                    "error": "æµ‹è¯•ç­–ç•¥ç”Ÿæˆå¤±è´¥",
                    "details": strategy_result
                }
            
            # 2. ç”Ÿæˆæ™ºèƒ½æµ‹è¯•ç”¨ä¾‹
            logger.info("ğŸ“ ç”Ÿæˆæ™ºèƒ½æµ‹è¯•ç”¨ä¾‹...")
            cases_result = await self.case_generator.generate_cases_for_remote(
                strategy_result,
                data.get("requirements", {})
            )
            
            if not cases_result.get("success", False):
                return {
                    "success": False,
                    "error": "æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¤±è´¥",
                    "details": cases_result
                }
            
            # 3. æ‰§è¡Œæµ‹è¯•
            logger.info("âš¡ å¯åŠ¨æ™ºèƒ½æµ‹è¯•æ‰§è¡Œ...")
            execution_config = data.get("execution_config", {"mode": "mixed"})
            execution_id = await self.execution_manager.execute_for_remote(
                cases_result.get("test_cases", []),
                execution_config
            )
            
            return {
                "success": True,
                "cycle_id": f"intelligent_cycle_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "strategy": strategy_result,
                "test_cases": cases_result,
                "execution": {
                    "execution_id": execution_id,
                    "status": "started",
                    "message": "æ™ºèƒ½æµ‹è¯•æ‰§è¡Œå·²å¯åŠ¨"
                },
                "summary": {
                    "total_test_cases": cases_result.get("total_cases", 0),
                    "coverage_target": strategy_result.get("coverage_target", 0),
                    "estimated_duration": cases_result.get("estimated_execution_time", {}),
                    "automation_rate": cases_result.get("automation_rate", 0)
                }
            }
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½æµ‹è¯•å‘¨æœŸæ‰§è¡Œå¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"æ™ºèƒ½æµ‹è¯•å‘¨æœŸæ‰§è¡Œå¤±è´¥: {e}"
            }
    
    async def _handle_legacy_request(self, request_type: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†åŸæœ‰çš„è¯·æ±‚ç±»å‹"""
        if request_type == "discover_tests":
            result = await self.discover_tests_by_project(data.get('project_info', {}))
            return {"success": True, "results": result}
        elif request_type == "execute_tests":
            result = await self.execute_test_plan(
                data.get('test_plan', {}),
                data.get('project_info', {})
            )
            return {"success": True, "results": result}
        else:
            return {
                "success": False,
                "error": f"æœªçŸ¥è¯·æ±‚ç±»å‹: {request_type}"
            }
# åˆ›å»ºå¢å¼ºçš„æµ‹è¯•ç®¡ç†å™¨å®ä¾‹
enhanced_test_manager_mcp = EnhancedTestManagerMCP()

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        "service": enhanced_test_manager_mcp.service_id,
        "version": enhanced_test_manager_mcp.version,
        "status": enhanced_test_manager_mcp.status,
        "timestamp": datetime.now().isoformat(),
        "capabilities": [
            "æ™ºèƒ½æµ‹è¯•ç­–ç•¥ç”Ÿæˆ",
            "æ™ºèƒ½æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ", 
            "å¼‚æ­¥æµ‹è¯•æ‰§è¡Œç®¡ç†",
            "å®æ—¶çŠ¶æ€ç›‘æ§",
            "è¯¦ç»†æŠ¥å‘Šç”Ÿæˆ"
        ]
    })

@app.route('/api/test/strategy', methods=['POST'])
def generate_strategy():
    """ç”Ÿæˆæµ‹è¯•ç­–ç•¥"""
    try:
        data = request.get_json()
=======
        # æµ‹è¯•ç±»å‹æ˜ å°„
        self.test_type_mapping = {
            "unit": "unit",
            "integration": "integration", 
            "comprehensive": "comprehensive",
            "smoke": "simple",
            "all": None
        }
        
        logger.info(f"âœ… Test Manager MCP åˆå§‹åŒ–å®Œæˆ")
    
    async def discover_tests_by_project(self, project_info):
        """æ ¹æ®é¡¹ç›®ä¿¡æ¯å‘ç°ç›¸å…³æµ‹è¯•"""
        try:
            project_name = project_info.get("name", "")
            project_type = project_info.get("type", "")
            complexity = project_info.get("complexity", "simple")
            
            # æ ¹æ®é¡¹ç›®ç±»å‹ç¡®å®šæµ‹è¯•ç­–ç•¥
            test_strategy = self._determine_test_strategy(project_type, complexity)
            
            # å‘ç°æµ‹è¯•
            tests = await self.test_manager.discover_tests(
                module_filter=test_strategy.get("module_filter"),
                test_type_filter=test_strategy.get("test_type")
            )
            
            # ä¸ºé¡¹ç›®ç”Ÿæˆç‰¹å®šçš„æµ‹è¯•è®¡åˆ’
            test_plan = self._generate_test_plan(project_info, tests)
            
            return {
                "success": True,
                "project_name": project_name,
                "test_strategy": test_strategy,
                "discovered_tests": len(tests),
                "test_plan": test_plan,
                "tests": tests
            }
            
        except Exception as e:
            logger.error(f"æµ‹è¯•å‘ç°å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "fallback_plan": self._create_fallback_test_plan(project_info)
            }
    
    def _determine_test_strategy(self, project_type, complexity):
        """ç¡®å®šæµ‹è¯•ç­–ç•¥"""
        strategies = {
            "game": {
                "module_filter": "game|ui|canvas",
                "test_type": "unit",
                "focus_areas": ["æ¸¸æˆé€»è¾‘", "UIäº¤äº’", "æ€§èƒ½æµ‹è¯•"]
            },
            "web_app": {
                "module_filter": "web|api|frontend",
                "test_type": "integration",
                "focus_areas": ["APIæµ‹è¯•", "å‰ç«¯æµ‹è¯•", "æ•°æ®åº“æµ‹è¯•"]
            },
            "ecommerce": {
                "module_filter": "ecommerce|payment|user",
                "test_type": "comprehensive",
                "focus_areas": ["æ”¯ä»˜æµç¨‹", "ç”¨æˆ·ç®¡ç†", "å®‰å…¨æµ‹è¯•"]
            },
            "api": {
                "module_filter": "api|backend|service",
                "test_type": "integration",
                "focus_areas": ["APIç«¯ç‚¹", "æ•°æ®éªŒè¯", "æ€§èƒ½æµ‹è¯•"]
            }
        }
        
        # æ ¹æ®å¤æ‚åº¦è°ƒæ•´ç­–ç•¥
        base_strategy = strategies.get(project_type, strategies["web_app"])
        
        if complexity == "simple":
            base_strategy["test_type"] = "simple"
        elif complexity == "complex":
            base_strategy["test_type"] = "comprehensive"
        
        return base_strategy
    
    def _generate_test_plan(self, project_info, discovered_tests):
        """ç”Ÿæˆæµ‹è¯•è®¡åˆ’"""
        project_name = project_info.get("name", "Unknown Project")
        
        # åˆ†ç±»æµ‹è¯•
        test_categories = {
            "unit_tests": [],
            "integration_tests": [],
            "ui_tests": [],
            "performance_tests": [],
            "security_tests": []
        }
        
        for test in discovered_tests:
            test_type = test.get("test_type", "unit")
            test_name = test.get("test_name", "")
            
            if "unit" in test_type or "unit" in test_name.lower():
                test_categories["unit_tests"].append(test)
            elif "integration" in test_type or "integration" in test_name.lower():
                test_categories["integration_tests"].append(test)
            elif "ui" in test_name.lower() or "frontend" in test_name.lower():
                test_categories["ui_tests"].append(test)
            elif "performance" in test_name.lower() or "load" in test_name.lower():
                test_categories["performance_tests"].append(test)
            elif "security" in test_name.lower() or "auth" in test_name.lower():
                test_categories["security_tests"].append(test)
            else:
                test_categories["unit_tests"].append(test)  # é»˜è®¤å½’ç±»ä¸ºå•å…ƒæµ‹è¯•
        
        # ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
        execution_phases = [
            {
                "phase": 1,
                "name": "å•å…ƒæµ‹è¯•",
                "tests": test_categories["unit_tests"],
                "parallel": True,
                "timeout": 300
            },
            {
                "phase": 2,
                "name": "é›†æˆæµ‹è¯•",
                "tests": test_categories["integration_tests"],
                "parallel": True,
                "timeout": 600
            },
            {
                "phase": 3,
                "name": "UIæµ‹è¯•",
                "tests": test_categories["ui_tests"],
                "parallel": False,
                "timeout": 900
            },
            {
                "phase": 4,
                "name": "æ€§èƒ½æµ‹è¯•",
                "tests": test_categories["performance_tests"],
                "parallel": False,
                "timeout": 1200
            },
            {
                "phase": 5,
                "name": "å®‰å…¨æµ‹è¯•",
                "tests": test_categories["security_tests"],
                "parallel": True,
                "timeout": 600
            }
        ]
        
        # è¿‡æ»¤æ‰æ²¡æœ‰æµ‹è¯•çš„é˜¶æ®µ
        execution_phases = [phase for phase in execution_phases if phase["tests"]]
        
        return {
            "project_name": project_name,
            "total_tests": len(discovered_tests),
            "test_categories": {k: len(v) for k, v in test_categories.items()},
            "execution_phases": execution_phases,
            "estimated_duration": sum(phase["timeout"] for phase in execution_phases),
            "recommended_parallel": len(discovered_tests) > 10
        }
    
    def _create_fallback_test_plan(self, project_info):
        """åˆ›å»ºå¤‡ç”¨æµ‹è¯•è®¡åˆ’"""
        project_name = project_info.get("name", "Unknown Project")
        project_type = project_info.get("type", "web_app")
        
        # åŸºäºé¡¹ç›®ç±»å‹çš„æ ‡å‡†æµ‹è¯•æ¨¡æ¿
        templates = {
            "game": [
                {"name": "æ¸¸æˆé€»è¾‘æµ‹è¯•", "type": "unit", "description": "æµ‹è¯•æ¸¸æˆæ ¸å¿ƒé€»è¾‘"},
                {"name": "UIäº¤äº’æµ‹è¯•", "type": "integration", "description": "æµ‹è¯•ç”¨æˆ·ç•Œé¢äº¤äº’"},
                {"name": "æ€§èƒ½æµ‹è¯•", "type": "performance", "description": "æµ‹è¯•æ¸¸æˆæ€§èƒ½"}
            ],
            "web_app": [
                {"name": "å‰ç«¯ç»„ä»¶æµ‹è¯•", "type": "unit", "description": "æµ‹è¯•å‰ç«¯ç»„ä»¶"},
                {"name": "APIæ¥å£æµ‹è¯•", "type": "integration", "description": "æµ‹è¯•APIæ¥å£"},
                {"name": "ç«¯åˆ°ç«¯æµ‹è¯•", "type": "e2e", "description": "æµ‹è¯•å®Œæ•´ç”¨æˆ·æµç¨‹"}
            ],
            "ecommerce": [
                {"name": "ç”¨æˆ·æ³¨å†Œç™»å½•æµ‹è¯•", "type": "integration", "description": "æµ‹è¯•ç”¨æˆ·è®¤è¯"},
                {"name": "å•†å“ç®¡ç†æµ‹è¯•", "type": "unit", "description": "æµ‹è¯•å•†å“CRUD"},
                {"name": "æ”¯ä»˜æµç¨‹æµ‹è¯•", "type": "integration", "description": "æµ‹è¯•æ”¯ä»˜åŠŸèƒ½"},
                {"name": "å®‰å…¨æµ‹è¯•", "type": "security", "description": "æµ‹è¯•ç³»ç»Ÿå®‰å…¨æ€§"}
            ]
        }
        
        test_template = templates.get(project_type, templates["web_app"])
        
        return {
            "project_name": project_name,
            "test_template": test_template,
            "total_template_tests": len(test_template),
            "note": "ä½¿ç”¨æ ‡å‡†æµ‹è¯•æ¨¡æ¿ï¼Œå»ºè®®æ ¹æ®å®é™…é¡¹ç›®è°ƒæ•´"
        }
    
    async def execute_test_plan(self, test_plan, project_info):
        """æ‰§è¡Œæµ‹è¯•è®¡åˆ’"""
        try:
            project_name = project_info.get("name", "Unknown Project")
            
            logger.info(f"ğŸ§ª å¼€å§‹æ‰§è¡Œæµ‹è¯•è®¡åˆ’: {project_name}")
            
            # æ‰§è¡Œæµ‹è¯•
            if "execution_phases" in test_plan:
                # æŒ‰é˜¶æ®µæ‰§è¡Œ
                results = await self._execute_phased_tests(test_plan["execution_phases"])
            else:
                # æ‰§è¡Œæ¨¡æ¿æµ‹è¯•
                results = await self._execute_template_tests(test_plan.get("test_template", []))
            
            # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
            test_report = self._generate_test_report(project_info, test_plan, results)
            
            return {
                "success": True,
                "project_name": project_name,
                "execution_results": results,
                "test_report": test_report,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "project_name": project_info.get("name", "Unknown Project"),
                "timestamp": datetime.now().isoformat()
            }
    
    async def _execute_phased_tests(self, execution_phases):
        """æŒ‰é˜¶æ®µæ‰§è¡Œæµ‹è¯•"""
        phase_results = []
        
        for phase in execution_phases:
            logger.info(f"ğŸ”„ æ‰§è¡Œæµ‹è¯•é˜¶æ®µ {phase['phase']}: {phase['name']}")
            
            try:
                # æ‰§è¡Œè¯¥é˜¶æ®µçš„æµ‹è¯•
                session = await self.test_manager.run_tests(
                    tests=phase["tests"],
                    parallel=phase["parallel"]
                )
                
                phase_result = {
                    "phase": phase["phase"],
                    "name": phase["name"],
                    "status": "completed",
                    "total_tests": len(phase["tests"]),
                    "passed": session.passed_tests if hasattr(session, 'passed_tests') else 0,
                    "failed": session.failed_tests if hasattr(session, 'failed_tests') else 0,
                    "duration": (session.end_time - session.start_time).total_seconds() if hasattr(session, 'end_time') and session.end_time else 0
                }
                
            except Exception as e:
                logger.error(f"é˜¶æ®µ {phase['phase']} æ‰§è¡Œå¤±è´¥: {e}")
                phase_result = {
                    "phase": phase["phase"],
                    "name": phase["name"],
                    "status": "failed",
                    "error": str(e),
                    "total_tests": len(phase["tests"]),
                    "passed": 0,
                    "failed": len(phase["tests"])
                }
            
            phase_results.append(phase_result)
        
        return phase_results
    
    async def _execute_template_tests(self, test_template):
        """æ‰§è¡Œæ¨¡æ¿æµ‹è¯•"""
        template_results = []
        
        for test_item in test_template:
            logger.info(f"ğŸ§ª æ‰§è¡Œæ¨¡æ¿æµ‹è¯•: {test_item['name']}")
            
            # æ¨¡æ‹Ÿæµ‹è¯•æ‰§è¡Œ
            import random
            import time
            
            start_time = time.time()
            
            # æ¨¡æ‹Ÿæµ‹è¯•æ‰§è¡Œæ—¶é—´
            await asyncio.sleep(random.uniform(0.1, 0.5))
            
            # æ¨¡æ‹Ÿæµ‹è¯•ç»“æœï¼ˆ90%æˆåŠŸç‡ï¼‰
            success = random.random() > 0.1
            
            end_time = time.time()
            
            result = {
                "name": test_item["name"],
                "type": test_item["type"],
                "description": test_item["description"],
                "status": "passed" if success else "failed",
                "duration": end_time - start_time,
                "timestamp": datetime.now().isoformat()
            }
            
            if not success:
                result["error"] = f"æ¨¡æ‹Ÿæµ‹è¯•å¤±è´¥: {test_item['name']}"
            
            template_results.append(result)
        
        return template_results
    
    def _generate_test_report(self, project_info, test_plan, results):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        project_name = project_info.get("name", "Unknown Project")
        
        # ç»Ÿè®¡ç»“æœ
        if isinstance(results, list) and results and "phase" in results[0]:
            # é˜¶æ®µæµ‹è¯•ç»“æœ
            total_tests = sum(r.get("total_tests", 0) for r in results)
            total_passed = sum(r.get("passed", 0) for r in results)
            total_failed = sum(r.get("failed", 0) for r in results)
            total_duration = sum(r.get("duration", 0) for r in results)
        else:
            # æ¨¡æ¿æµ‹è¯•ç»“æœ
            total_tests = len(results)
            total_passed = sum(1 for r in results if r.get("status") == "passed")
            total_failed = sum(1 for r in results if r.get("status") == "failed")
            total_duration = sum(r.get("duration", 0) for r in results)
        
        success_rate = (total_passed / total_tests * 100) if total_tests > 0 else 0
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            "project_name": project_name,
            "test_execution_summary": {
                "total_tests": total_tests,
                "passed": total_passed,
                "failed": total_failed,
                "success_rate": round(success_rate, 2),
                "total_duration": round(total_duration, 2),
                "execution_date": datetime.now().isoformat()
            },
            "test_plan_info": {
                "plan_type": "phased" if "execution_phases" in test_plan else "template",
                "total_phases": len(test_plan.get("execution_phases", [])),
                "estimated_duration": test_plan.get("estimated_duration", 0)
            },
            "detailed_results": results,
            "recommendations": self._generate_recommendations(success_rate, results),
            "next_steps": self._generate_next_steps(project_info, success_rate)
        }
        
        return report
    
    def _generate_recommendations(self, success_rate, results):
        """ç”Ÿæˆæµ‹è¯•å»ºè®®"""
        recommendations = []
        
        if success_rate < 70:
            recommendations.append("æµ‹è¯•æˆåŠŸç‡è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥ä»£ç è´¨é‡å’Œæµ‹è¯•ç”¨ä¾‹")
        elif success_rate < 90:
            recommendations.append("æµ‹è¯•æˆåŠŸç‡ä¸­ç­‰ï¼Œå»ºè®®ä¼˜åŒ–å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹")
        else:
            recommendations.append("æµ‹è¯•æˆåŠŸç‡è‰¯å¥½ï¼Œå¯ä»¥è€ƒè™‘å¢åŠ æ›´å¤šæµ‹è¯•è¦†ç›–")
        
        # åˆ†æå¤±è´¥çš„æµ‹è¯•
        if isinstance(results, list):
            failed_tests = [r for r in results if r.get("status") == "failed"]
            if failed_tests:
                recommendations.append(f"å‘ç° {len(failed_tests)} ä¸ªå¤±è´¥æµ‹è¯•ï¼Œå»ºè®®ä¼˜å…ˆä¿®å¤")
        
        return recommendations
    
    def _generate_next_steps(self, project_info, success_rate):
        """ç”Ÿæˆä¸‹ä¸€æ­¥å»ºè®®"""
        next_steps = []
        
        if success_rate >= 90:
            next_steps.append("âœ… æµ‹è¯•é€šè¿‡ï¼Œå¯ä»¥è¿›è¡Œéƒ¨ç½²")
            next_steps.append("ğŸš€ å»ºè®®æ‰§è¡Œéƒ¨ç½²å‰çš„æœ€ç»ˆæ£€æŸ¥")
        elif success_rate >= 70:
            next_steps.append("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œå»ºè®®ä¿®å¤åé‡æ–°æµ‹è¯•")
            next_steps.append("ğŸ”§ æ£€æŸ¥å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹å¹¶ä¿®å¤ä»£ç ")
        else:
            next_steps.append("âŒ æµ‹è¯•å¤±è´¥ç‡è¾ƒé«˜ï¼Œä¸å»ºè®®éƒ¨ç½²")
            next_steps.append("ğŸ› ï¸ éœ€è¦å¤§å¹…æ”¹è¿›ä»£ç è´¨é‡")
            next_steps.append("ğŸ“‹ å»ºè®®é‡æ–°å®¡æŸ¥é¡¹ç›®éœ€æ±‚å’Œè®¾è®¡")
        
        return next_steps

# Flask API ç«¯ç‚¹
test_manager_mcp = TestManagerMCP()

@app.route('/health')
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        "service": test_manager_mcp.service_id,
        "status": "healthy",
        "version": test_manager_mcp.version,
        "timestamp": datetime.now().isoformat()
    })

@app.route('/api/test/discover', methods=['POST'])
def discover_tests():
    """å‘ç°æµ‹è¯•"""
    try:
        data = request.get_json()
        project_info = data.get('project_info', {})
        
>>>>>>> fc1525368711230da2586d4c928810f1e886598c
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        result = loop.run_until_complete(
<<<<<<< HEAD
            enhanced_test_manager_mcp.strategy_generator.generate_strategy_for_remote(
                data.get('project_info', {})
            )
        )
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/test/cases', methods=['POST'])
def generate_cases():
    """ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹"""
    try:
        data = request.get_json()
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        result = loop.run_until_complete(
            enhanced_test_manager_mcp.case_generator.generate_cases_for_remote(
                data.get('strategy', {}),
                data.get('requirements', {})
            )
        )
        return jsonify(result)
    except Exception as e:
=======
            test_manager_mcp.discover_tests_by_project(project_info)
        )
        
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"æµ‹è¯•å‘ç°APIå¤±è´¥: {e}")
>>>>>>> fc1525368711230da2586d4c928810f1e886598c
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/test/execute', methods=['POST'])
def execute_tests():
    """æ‰§è¡Œæµ‹è¯•"""
    try:
        data = request.get_json()
<<<<<<< HEAD
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        execution_id = loop.run_until_complete(
            enhanced_test_manager_mcp.execution_manager.execute_for_remote(
                data.get('test_cases', []),
                data.get('execution_config', {})
            )
        )
        return jsonify({
            "success": True,
            "execution_id": execution_id,
            "message": "æµ‹è¯•æ‰§è¡Œå·²å¯åŠ¨"
        })
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/test/status/<execution_id>', methods=['GET'])
def get_execution_status(execution_id):
    """è·å–æ‰§è¡ŒçŠ¶æ€"""
    try:
        result = enhanced_test_manager_mcp.execution_manager.get_execution_status(execution_id)
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/test/report/<execution_id>', methods=['GET'])
def get_execution_report(execution_id):
    """è·å–æ‰§è¡ŒæŠ¥å‘Š"""
    try:
        result = enhanced_test_manager_mcp.execution_manager.get_execution_report(execution_id)
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/test/executions', methods=['GET'])
def get_active_executions():
    """è·å–æ´»è·ƒæ‰§è¡Œ"""
    try:
        result = enhanced_test_manager_mcp.execution_manager.get_active_executions()
        return jsonify({"success": True, "active_executions": result})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/test/intelligent-cycle', methods=['POST'])
def execute_intelligent_cycle():
    """æ‰§è¡Œå®Œæ•´æ™ºèƒ½æµ‹è¯•å‘¨æœŸ"""
    try:
        data = request.get_json()
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        result = loop.run_until_complete(
            enhanced_test_manager_mcp._execute_full_intelligent_cycle(data)
        )
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/mcp/process', methods=['POST'])
def process_mcp_request():
    """å¤„ç†MCPè¯·æ±‚ - å…¼å®¹åŸæœ‰æ¥å£"""
    try:
        data = request.get_json()
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        result = loop.run_until_complete(
            enhanced_test_manager_mcp.process(data)
        )
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

if __name__ == '__main__':
    logger.info("ğŸš€ å¯åŠ¨ Enhanced Test Manager MCP...")
    logger.info(f"ğŸ“ æœåŠ¡åœ°å€: http://0.0.0.0:8097")
    logger.info(f"ğŸ§  æ™ºèƒ½æµ‹è¯•ç­–ç•¥ç”Ÿæˆ: /api/test/strategy")
    logger.info(f"ğŸ“ æ™ºèƒ½æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ: /api/test/cases")
    logger.info(f"âš¡ å¼‚æ­¥æµ‹è¯•æ‰§è¡Œ: /api/test/execute")
    logger.info(f"ğŸ“Š å®Œæ•´æ™ºèƒ½å‘¨æœŸ: /api/test/intelligent-cycle")
    
    app.run(host='0.0.0.0', port=8097, debug=False)
=======
        test_plan = data.get('test_plan', {})
        project_info = data.get('project_info', {})
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        result = loop.run_until_complete(
            test_manager_mcp.execute_test_plan(test_plan, project_info)
        )
        
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"æµ‹è¯•æ‰§è¡ŒAPIå¤±è´¥: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/test/full-cycle', methods=['POST'])
def full_test_cycle():
    """å®Œæ•´æµ‹è¯•å‘¨æœŸï¼šå‘ç° + æ‰§è¡Œ"""
    try:
        data = request.get_json()
        project_info = data.get('project_info', {})
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        # 1. å‘ç°æµ‹è¯•
        discovery_result = loop.run_until_complete(
            test_manager_mcp.discover_tests_by_project(project_info)
        )
        
        if not discovery_result["success"]:
            return jsonify(discovery_result), 500
        
        # 2. æ‰§è¡Œæµ‹è¯•
        test_plan = discovery_result.get("test_plan", discovery_result.get("fallback_plan", {}))
        execution_result = loop.run_until_complete(
            test_manager_mcp.execute_test_plan(test_plan, project_info)
        )
        
        # 3. åˆå¹¶ç»“æœ
        full_result = {
            "success": execution_result["success"],
            "project_name": project_info.get("name", "Unknown Project"),
            "discovery_phase": discovery_result,
            "execution_phase": execution_result,
            "timestamp": datetime.now().isoformat()
        }
        
        return jsonify(full_result)
        
    except Exception as e:
        logger.error(f"å®Œæ•´æµ‹è¯•å‘¨æœŸAPIå¤±è´¥: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/mcp/request', methods=['POST'])
def handle_mcp_request():
    """å¤„ç†MCPè¯·æ±‚"""
    try:
        data = request.get_json()
        action = data.get('action')
        params = data.get('params', {})
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        if action == "discover_tests":
            result = loop.run_until_complete(
                test_manager_mcp.discover_tests_by_project(params.get('project_info', {}))
            )
            return jsonify({"success": True, "results": result})
        
        elif action == "execute_tests":
            result = loop.run_until_complete(
                test_manager_mcp.execute_test_plan(
                    params.get('test_plan', {}),
                    params.get('project_info', {})
                )
            )
            return jsonify({"success": True, "results": result})
        
        elif action == "full_test_cycle":
            # å®Œæ•´æµ‹è¯•å‘¨æœŸ
            project_info = params.get('project_info', {})
            
            discovery_result = loop.run_until_complete(
                test_manager_mcp.discover_tests_by_project(project_info)
            )
            
            if discovery_result["success"]:
                test_plan = discovery_result.get("test_plan", discovery_result.get("fallback_plan", {}))
                execution_result = loop.run_until_complete(
                    test_manager_mcp.execute_test_plan(test_plan, project_info)
                )
                
                result = {
                    "discovery": discovery_result,
                    "execution": execution_result
                }
            else:
                result = {"discovery": discovery_result, "execution": None}
            
            return jsonify({"success": True, "results": result})
        
        else:
            return jsonify({"success": False, "error": f"æœªçŸ¥æ“ä½œ: {action}"}), 400
            
    except Exception as e:
        logger.error(f"å¤„ç†MCPè¯·æ±‚å¤±è´¥: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

if __name__ == '__main__':
    logger.info("ğŸš€ å¯åŠ¨ Test Manager MCP...")
    logger.info(f"ğŸ“ æœåŠ¡åœ°å€: http://0.0.0.0:8097")
    
    app.run(host='0.0.0.0', port=8097, debug=False)

>>>>>>> fc1525368711230da2586d4c928810f1e886598c
